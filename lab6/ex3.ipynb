{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils.convert import from_scipy_sparse_matrix, to_scipy_sparse_matrix\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch_sparse\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.loader import ClusterData, ClusterLoader\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('ACM.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Attributes']\n",
    "A = data['Network']\n",
    "labels = data['Label']\n",
    "\n",
    "X = torch.from_numpy(X.todense()).float() \n",
    "edge_index, edge_weight = from_scipy_sparse_matrix(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=X, edge_index=edge_index, edge_weight=edge_weight, y=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16484, 8337]), (1, 16484), (1, 16484), (16484, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, A[0].shape, A[1].shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0414, 0.0452, 0.0460, 0.0474, 0.0476, 0.0476, 0.0478, 0.0480,\n",
       "        0.0483, 0.0484, 0.0487, 0.0489, 0.0491, 0.0492, 0.0493, 0.0494, 0.0496,\n",
       "        0.0497, 0.0500, 0.0501, 0.0502, 0.0503, 0.0504, 0.0505, 0.0507, 0.0510,\n",
       "        0.0511, 0.0513, 0.0514, 0.0515, 0.0516, 0.0516, 0.0517, 0.0518, 0.0519,\n",
       "        0.0520, 0.0521, 0.0521, 0.0522, 0.0523, 0.0523, 0.0525, 0.0526, 0.0526,\n",
       "        0.0528, 0.0529, 0.0531, 0.0531, 0.0532, 0.0533, 0.0534, 0.0535, 0.0536,\n",
       "        0.0538, 0.0538, 0.0539, 0.0540, 0.0541, 0.0542, 0.0542, 0.0543, 0.0544,\n",
       "        0.0545, 0.0546, 0.0546, 0.0547, 0.0548, 0.0549, 0.0550, 0.0551, 0.0552,\n",
       "        0.0553, 0.0554, 0.0555, 0.0556, 0.0556, 0.0557, 0.0558, 0.0559, 0.0560,\n",
       "        0.0561, 0.0562, 0.0563, 0.0563, 0.0564, 0.0565, 0.0566, 0.0567, 0.0568,\n",
       "        0.0569, 0.0570, 0.0571, 0.0572, 0.0573, 0.0574, 0.0574, 0.0575, 0.0576,\n",
       "        0.0577, 0.0578, 0.0579, 0.0581, 0.0582, 0.0583, 0.0584, 0.0585, 0.0586,\n",
       "        0.0587, 0.0588, 0.0589, 0.0590, 0.0591, 0.0592, 0.0593, 0.0594, 0.0595,\n",
       "        0.0597, 0.0598, 0.0599, 0.0600, 0.0601, 0.0602, 0.0603, 0.0604, 0.0605,\n",
       "        0.0606, 0.0607, 0.0609, 0.0610, 0.0612, 0.0613, 0.0614, 0.0615, 0.0617,\n",
       "        0.0618, 0.0619, 0.0620, 0.0621, 0.0624, 0.0625, 0.0626, 0.0627, 0.0629,\n",
       "        0.0630, 0.0631, 0.0632, 0.0634, 0.0635, 0.0636, 0.0638, 0.0639, 0.0640,\n",
       "        0.0642, 0.0643, 0.0644, 0.0645, 0.0647, 0.0648, 0.0650, 0.0651, 0.0652,\n",
       "        0.0654, 0.0655, 0.0657, 0.0658, 0.0661, 0.0662, 0.0664, 0.0665, 0.0667,\n",
       "        0.0668, 0.0670, 0.0671, 0.0673, 0.0674, 0.0676, 0.0677, 0.0679, 0.0680,\n",
       "        0.0682, 0.0684, 0.0685, 0.0687, 0.0688, 0.0690, 0.0692, 0.0693, 0.0695,\n",
       "        0.0697, 0.0698, 0.0700, 0.0702, 0.0704, 0.0705, 0.0707, 0.0709, 0.0711,\n",
       "        0.0712, 0.0714, 0.0716, 0.0718, 0.0720, 0.0722, 0.0724, 0.0725, 0.0727,\n",
       "        0.0729, 0.0731, 0.0733, 0.0735, 0.0737, 0.0739, 0.0741, 0.0743, 0.0745,\n",
       "        0.0747, 0.0750, 0.0752, 0.0754, 0.0756, 0.0758, 0.0760, 0.0762, 0.0765,\n",
       "        0.0767, 0.0769, 0.0772, 0.0774, 0.0776, 0.0778, 0.0781, 0.0783, 0.0786,\n",
       "        0.0788, 0.0791, 0.0793, 0.0796, 0.0798, 0.0801, 0.0803, 0.0806, 0.0808,\n",
       "        0.0811, 0.0814, 0.0816, 0.0819, 0.0822, 0.0825, 0.0828, 0.0828, 0.0830,\n",
       "        0.0833, 0.0836, 0.0839, 0.0842, 0.0845, 0.0848, 0.0851, 0.0854, 0.0857,\n",
       "        0.0861, 0.0864, 0.0867, 0.0870, 0.0874, 0.0877, 0.0880, 0.0884, 0.0887,\n",
       "        0.0891, 0.0894, 0.0898, 0.0902, 0.0904, 0.0905, 0.0909, 0.0913, 0.0917,\n",
       "        0.0921, 0.0925, 0.0928, 0.0933, 0.0937, 0.0941, 0.0945, 0.0947, 0.0949,\n",
       "        0.0951, 0.0952, 0.0953, 0.0956, 0.0958, 0.0960, 0.0962, 0.0966, 0.0967,\n",
       "        0.0968, 0.0971, 0.0974, 0.0976, 0.0977, 0.0981, 0.0983, 0.0984, 0.0985,\n",
       "        0.0987, 0.0989, 0.0990, 0.0993, 0.0994, 0.0995, 0.1000, 0.1003, 0.1004,\n",
       "        0.1005, 0.1008, 0.1010, 0.1014, 0.1015, 0.1021, 0.1022, 0.1026, 0.1030,\n",
       "        0.1031, 0.1033, 0.1034, 0.1036, 0.1037, 0.1038, 0.1040, 0.1041, 0.1043,\n",
       "        0.1044, 0.1045, 0.1048, 0.1050, 0.1051, 0.1054, 0.1056, 0.1057, 0.1060,\n",
       "        0.1061, 0.1063, 0.1064, 0.1066, 0.1068, 0.1071, 0.1072, 0.1075, 0.1077,\n",
       "        0.1078, 0.1080, 0.1081, 0.1083, 0.1085, 0.1086, 0.1088, 0.1089, 0.1091,\n",
       "        0.1093, 0.1094, 0.1096, 0.1098, 0.1103, 0.1104, 0.1106, 0.1108, 0.1109,\n",
       "        0.1111, 0.1113, 0.1115, 0.1116, 0.1118, 0.1120, 0.1122, 0.1123, 0.1125,\n",
       "        0.1127, 0.1129, 0.1130, 0.1132, 0.1134, 0.1140, 0.1141, 0.1143, 0.1145,\n",
       "        0.1147, 0.1149, 0.1151, 0.1153, 0.1155, 0.1157, 0.1159, 0.1162, 0.1164,\n",
       "        0.1166, 0.1168, 0.1170, 0.1172, 0.1179, 0.1181, 0.1183, 0.1187, 0.1189,\n",
       "        0.1191, 0.1193, 0.1195, 0.1197, 0.1200, 0.1204, 0.1206, 0.1208, 0.1210,\n",
       "        0.1213, 0.1215, 0.1217, 0.1219, 0.1222, 0.1224, 0.1229, 0.1231, 0.1233,\n",
       "        0.1238, 0.1240, 0.1242, 0.1243, 0.1248, 0.1250, 0.1255, 0.1257, 0.1260,\n",
       "        0.1262, 0.1265, 0.1267, 0.1270, 0.1273, 0.1275, 0.1278, 0.1280, 0.1283,\n",
       "        0.1286, 0.1288, 0.1291, 0.1294, 0.1299, 0.1302, 0.1305, 0.1307, 0.1313,\n",
       "        0.1316, 0.1322, 0.1325, 0.1327, 0.1330, 0.1333, 0.1336, 0.1339, 0.1345,\n",
       "        0.1348, 0.1351, 0.1355, 0.1357, 0.1358, 0.1361, 0.1364, 0.1367, 0.1370,\n",
       "        0.1374, 0.1377, 0.1380, 0.1381, 0.1383, 0.1387, 0.1390, 0.1393, 0.1397,\n",
       "        0.1400, 0.1404, 0.1407, 0.1411, 0.1414, 0.1418, 0.1421, 0.1421, 0.1425,\n",
       "        0.1427, 0.1429, 0.1432, 0.1433, 0.1436, 0.1440, 0.1440, 0.1443, 0.1447,\n",
       "        0.1448, 0.1451, 0.1452, 0.1455, 0.1459, 0.1460, 0.1463, 0.1466, 0.1466,\n",
       "        0.1470, 0.1474, 0.1476, 0.1478, 0.1482, 0.1483, 0.1487, 0.1489, 0.1491,\n",
       "        0.1495, 0.1499, 0.1500, 0.1503, 0.1504, 0.1506, 0.1508, 0.1512, 0.1515,\n",
       "        0.1516, 0.1521, 0.1525, 0.1531, 0.1538, 0.1539, 0.1541, 0.1543, 0.1545,\n",
       "        0.1548, 0.1552, 0.1557, 0.1558, 0.1560, 0.1562, 0.1564, 0.1567, 0.1571,\n",
       "        0.1576, 0.1577, 0.1581, 0.1586, 0.1586, 0.1591, 0.1592, 0.1594, 0.1596,\n",
       "        0.1601, 0.1606, 0.1606, 0.1608, 0.1612, 0.1615, 0.1617, 0.1617, 0.1620,\n",
       "        0.1622, 0.1625, 0.1627, 0.1628, 0.1633, 0.1637, 0.1638, 0.1642, 0.1644,\n",
       "        0.1650, 0.1655, 0.1657, 0.1661, 0.1662, 0.1664, 0.1667, 0.1672, 0.1672,\n",
       "        0.1674, 0.1677, 0.1678, 0.1680, 0.1682, 0.1684, 0.1690, 0.1696, 0.1696,\n",
       "        0.1709, 0.1712, 0.1715, 0.1721, 0.1723, 0.1728, 0.1734, 0.1735, 0.1741,\n",
       "        0.1747, 0.1750, 0.1753, 0.1754, 0.1756, 0.1761, 0.1768, 0.1771, 0.1774,\n",
       "        0.1775, 0.1782, 0.1789, 0.1793, 0.1796, 0.1803, 0.1809, 0.1811, 0.1812,\n",
       "        0.1816, 0.1818, 0.1822, 0.1826, 0.1833, 0.1841, 0.1849, 0.1850, 0.1857,\n",
       "        0.1864, 0.1865, 0.1871, 0.1873, 0.1881, 0.1886, 0.1890, 0.1894, 0.1898,\n",
       "        0.1903, 0.1907, 0.1916, 0.1917, 0.1925, 0.1928, 0.1933, 0.1941, 0.1943,\n",
       "        0.1952, 0.1953, 0.1957, 0.1961, 0.1966, 0.1968, 0.1970, 0.1971, 0.1980,\n",
       "        0.1982, 0.1988, 0.1990, 0.1991, 0.2000, 0.2005, 0.2009, 0.2010, 0.2018,\n",
       "        0.2020, 0.2023, 0.2031, 0.2037, 0.2041, 0.2046, 0.2052, 0.2056, 0.2060,\n",
       "        0.2063, 0.2065, 0.2074, 0.2075, 0.2085, 0.2090, 0.2097, 0.2106, 0.2108,\n",
       "        0.2120, 0.2127, 0.2132, 0.2143, 0.2144, 0.2154, 0.2157, 0.2160, 0.2165,\n",
       "        0.2169, 0.2182, 0.2188, 0.2195, 0.2209, 0.2222, 0.2224, 0.2236, 0.2242,\n",
       "        0.2243, 0.2250, 0.2265, 0.2274, 0.2279, 0.2281, 0.2294, 0.2309, 0.2315,\n",
       "        0.2321, 0.2325, 0.2328, 0.2335, 0.2337, 0.2341, 0.2343, 0.2350, 0.2357,\n",
       "        0.2372, 0.2374, 0.2378, 0.2379, 0.2389, 0.2390, 0.2394, 0.2408, 0.2417,\n",
       "        0.2421, 0.2425, 0.2430, 0.2433, 0.2441, 0.2443, 0.2449, 0.2458, 0.2462,\n",
       "        0.2474, 0.2481, 0.2481, 0.2483, 0.2491, 0.2500, 0.2520, 0.2526, 0.2540,\n",
       "        0.2561, 0.2572, 0.2582, 0.2592, 0.2604, 0.2611, 0.2621, 0.2626, 0.2649,\n",
       "        0.2673, 0.2683, 0.2697, 0.2700, 0.2705, 0.2722, 0.2727, 0.2728, 0.2747,\n",
       "        0.2774, 0.2798, 0.2801, 0.2828, 0.2857, 0.2873, 0.2887, 0.2904, 0.2917,\n",
       "        0.2928, 0.2942, 0.2949, 0.2970, 0.2981, 0.3000, 0.3015, 0.3032, 0.3050,\n",
       "        0.3062, 0.3086, 0.3114, 0.3119, 0.3123, 0.3128, 0.3145, 0.3162, 0.3198,\n",
       "        0.3203, 0.3213, 0.3244, 0.3273, 0.3277, 0.3288, 0.3293, 0.3299, 0.3313,\n",
       "        0.3333, 0.3354, 0.3369, 0.3381, 0.3397, 0.3419, 0.3430, 0.3441, 0.3464,\n",
       "        0.3482, 0.3487, 0.3508, 0.3518, 0.3536, 0.3560, 0.3563, 0.3592, 0.3651,\n",
       "        0.3665, 0.3693, 0.3714, 0.3737, 0.3750, 0.3780, 0.3810, 0.3841, 0.3849,\n",
       "        0.3873, 0.3922, 0.3939, 0.4000, 0.4009, 0.4045, 0.4061, 0.4082, 0.4121,\n",
       "        0.4160, 0.4170, 0.4193, 0.4201, 0.4243, 0.4264, 0.4313, 0.4330, 0.4364,\n",
       "        0.4423, 0.4472, 0.4523, 0.4545, 0.4575, 0.4588, 0.4629, 0.4650, 0.4685,\n",
       "        0.4714, 0.4743, 0.4747, 0.4804, 0.4815, 0.4851, 0.4867, 0.4932, 0.5000,\n",
       "        0.5071, 0.5145, 0.5164, 0.5222, 0.5241, 0.5298, 0.5303, 0.5345, 0.5388,\n",
       "        0.5477, 0.5547, 0.5571, 0.5657, 0.5669, 0.5774, 0.5835, 0.5883, 0.6000,\n",
       "        0.6030, 0.6124, 0.6255, 0.6299, 0.6325, 0.6396, 0.6489, 0.6667, 0.6708,\n",
       "        0.6882, 0.7071, 0.7276, 0.7500, 0.7559, 0.7746, 0.8018, 0.8165, 0.8660,\n",
       "        0.9487, 1.0000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GAE_Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels=128, out_channels=64):\n",
    "        super(GAE_Encoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        return x\n",
    "    \n",
    "dummy_input = torch.rand(100, 50)\n",
    "dummy_edge_index = torch.randint(0, 100, (2, 100))\n",
    "encoder = GAE_Encoder(50, 128, 64)\n",
    "output = encoder(dummy_input, dummy_edge_index)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GAE_AttrDecoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels=64, out_channels=128):\n",
    "        super(GAE_AttrDecoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        \n",
    "    def forward(self, z, edge_index):\n",
    "        x_hat = F.relu(self.conv1(z, edge_index))\n",
    "        x_hat = F.relu(self.conv2(x_hat, edge_index))\n",
    "        return x_hat\n",
    "    \n",
    "dummy_input = torch.rand(100, 64)\n",
    "decoder = GAE_AttrDecoder(64, 64, 128)\n",
    "output = decoder(dummy_input, dummy_edge_index)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GAE_StructDecoder(nn.Module):\n",
    "    def __init__(self, channels=64):\n",
    "        super(GAE_StructDecoder, self).__init__()\n",
    "        self.conv = GCNConv(channels, channels)\n",
    "        \n",
    "    def forward(self, z, edge_index):\n",
    "        z_hat = F.relu(self.conv(z, edge_index))\n",
    "        return z_hat @ z_hat.t()\n",
    "\n",
    "dummy_input = torch.rand(100, 64)\n",
    "decoder = GAE_StructDecoder(64)\n",
    "output = decoder(dummy_input, dummy_edge_index)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 50]), torch.Size([100, 100]), torch.Size([100, 64]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GraphAutoencoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels=128, out_channels=64):\n",
    "        super(GraphAutoencoder, self).__init__()\n",
    "        self.encoder = GAE_Encoder(in_channels, hidden_channels, out_channels)\n",
    "        self.attr_decoder = GAE_AttrDecoder(in_channels=out_channels, hidden_channels=hidden_channels, out_channels=in_channels)\n",
    "        self.struct_decoder = GAE_StructDecoder(channels=out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        z = self.encoder(x, edge_index)\n",
    "        \n",
    "        X_hat = self.attr_decoder(z, edge_index)\n",
    "        \n",
    "        A_hat = self.struct_decoder(z, edge_index)\n",
    "        \n",
    "        return X_hat, A_hat, z\n",
    "    \n",
    "dummy_input = torch.rand(100, 50)\n",
    "dummy_edge_index = torch.randint(0, 100, (2, 100))\n",
    "model = GraphAutoencoder(50, 128, 64)\n",
    "X_hat, A_hat, z = model(dummy_input, dummy_edge_index)\n",
    "X_hat.shape, A_hat.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gae_loss(x, x_hat, a, a_hat, alpha=0.8):\n",
    "    attr_diff = x - x_hat\n",
    "    attr_loss = torch.norm(attr_diff, p='fro')**2   \n",
    "    \n",
    "    struct_diff = a - a_hat\n",
    "    struct_loss = torch.norm(struct_diff, p='fro')**2\n",
    "    \n",
    "    return alpha * attr_loss + (1 - alpha) * struct_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_node_reconstruction_errors(x, x_hat, A, A_hat):\n",
    "    attr_errors = torch.sum((x - x_hat)**2, dim=1)\n",
    "    struct_errors = torch.sum((A - A_hat)**2, dim=1)\n",
    "\n",
    "    total_errors = attr_errors + struct_errors\n",
    "    return total_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/envs/aienv/lib/python3.11/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
      "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"
     ]
    }
   ],
   "source": [
    "loader = NeighborLoader(data, num_neighbors=[15, 10], batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [00:51<00:00, 10.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 531079.8444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [00:50<00:00, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 527126.2182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [00:50<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 526235.4852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [00:51<00:00, 10.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 523778.7846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [00:50<00:00, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 522340.9470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model = GraphAutoencoder(in_channels=X.shape[1], hidden_channels=128, out_channels=64)\n",
    "model = model.to(device) \n",
    "optimizer = Adam(model.parameters(), lr=0.004)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(loader):  \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_x = batch.x.to(device)\n",
    "        batch_edge_index = batch.edge_index.to(device)\n",
    "        \n",
    "        x_hat, a_hat, z = model(batch_x, batch_edge_index)\n",
    "        \n",
    "        a = to_scipy_sparse_matrix(batch_edge_index).todense()\n",
    "        a = torch.from_numpy(a).float().to(device)\n",
    "        \n",
    "        loss = gae_loss(batch_x, x_hat, a, a_hat)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x_hat, a_hat, z = model(data.x.to(device), data.edge_index.to(device))\n",
    "            loss = gae_loss(data.x.to(device), x_hat, a, a_hat)\n",
    "            errors = compute_node_reconstruction_errors(data.x.to(device), x_hat, a, a_hat)\n",
    "            errors = errors.cpu().numpy()\n",
    "            labels = data.y.cpu().numpy()\n",
    "            auc = roc_auc_score(labels, errors)\n",
    "    \n",
    "    print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
